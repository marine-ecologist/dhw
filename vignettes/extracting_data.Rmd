---
title: "Extracting SST and spatial data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Extracting SST and spatial data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
library(dhw)
library(sf)
library(tidyverse)
library(terra)
```

### Extract GBR spatial data

Use this function to download the GBR Reefs dataset via eAtlas. Several versions of the GBRMPA shp file exist, this version from eAtlas include the Torres Straits:

> This dataset consists of a shapefile of the reefs, islands, sand banks, cays and rocks of the whole Great Barrier Reef (GBR) including Torres Strait. This dataset is an extension of the mapping in the GBR Marine Park to include Torres Strait. The Torres Strait region was mapped at a scale of 1:50,000 (Lawrey, E. P., Stewart M., 2016) and these new features are referred to as the "Torres Strait Reef and Island Features" dataset. The Complete GBR Reef and Island Features dataset integrates the "Torres Strait Reef and Island Features" dataset with the existing "GBR Features" (Great Barrier Reef Marine Park Authority, 2007) to create a single composite dataset of the whole Great Barrier Reef.

for metadata see here:

[Complete Great Barrier Reef (GBR) Island and Reef Feature boundaries including Torres Strait Version 1b (NESP TWQ 3.13, AIMS, TSRA, GBRMPA)](https://researchdata.edu.au/complete-great-barrier-tsra-gbrmpa/675397)

Either combined or

```{r, eval=TRUE}

#gbr_reefs <- download_gbr_spatial(return="combined")
gbr_reefs <- download_gbr_spatial(return="base")

gbr_reefs

```

Set up a boundary to mask the raster data by buffering a 1km concave hull surrounding the GBR Reefs:

```{r, fig.width=7, fig.height=8}

gbr_reefs_border <- gbr_reefs |> 
  st_make_valid() |> 
  dplyr::filter(FEAT_NAME %in% c("Reef", "Terrestrial Reef")) 

gbr_reefs_hull <- gbr_reefs_border |> 
  concaveman::concaveman() |> 
  st_make_valid()

gbr_reefs_hull_buffered <- gbr_reefs_hull |> 
  st_buffer(1000) 

ggplot() + theme_bw() +
  geom_sf(data=gbr_reefs_hull_buffered,  fill="turquoise3") +
  geom_sf(data=gbr_reefs_hull, fill="lightblue") +
  geom_sf(data=gbr_reefs_border, fill="black") 
  


```

### Downloading and extracting SST data

NOAA provide many options for downloading SST data. [ERDAPP](https://www.ncei.noaa.gov/erddap/) via the `rerdapp` library is very useful for smaller requests, but (in my experience) downloading long-time series or large spatial extents of data can result in signficant timeouts.

Below are three helper functions that directly download CRW, OISST, and ERA5 datasets at global scales:

#### Extract NOAA CoralTemp spatial data

`download_CoralTemp()` pulls global data from the `ncei` https as follows:

```{r, eval=FALSE}



download_CoralTemp(url = "https://www.ncei.noaa.gov/thredds-ocean/fileServer/crw/5km/v3.1/nc/v1.0/daily/",
                   start_date = "2024-01-01",
                   end_date = "2024-12-31",
                   dest_dir = "/Volumes/Extreme_SSD/dhw/CRW/2024/",
                   variable = "sst",
                   mc.cores = 1)



```

the full global dataset for four variables (sst, ssta, hs, dhw) is 520.78GB in individual ~10-11MB .nc files. 


Alternatively, `cdo` offers a much faster workflow using `cdo mergetime *.nc outfile` and cropped to the GBR extent using`remapbil,target_grid_file.nc input.nc regridded_output.nc` (note: CDO does not directly support cropping to irregular polygons, so remapbil sets to the extent (bbox).


```{r, eval=FALSE}


```



#### Extract OISST

`download_OISST()` pulls global data from the `ncei` https as follows:


```{r, eval=FALSE}



download_OISST(url = "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/",
               start_date = "2024-01-01",
               end_date = "2024-12-31",
               dest_dir = "/Volumes/Extreme_SSD/dhw/OISST/2024/",
               mc.cores = 12)


```

the full global dataset is 26.39GB in individual ~10-11MB .nc files. 

as with CoralTemp, the output rasters can be merged by time using `terra::mosaic(rasters)` and `terra::crop()`. 

```{r, eval=FALSE}

process_OISST <- function(input, output, variable = "sst", combinedfilename = NULL) {
  # Ensure the output directory exists
  dir.create(output, recursive = TRUE, showWarnings = FALSE)
  
  
  temp_file <- file.path(tempdir(), "gbr_reefs_shp.gpkg")

  # Check if the file already exists
  if (!file.exists(temp_file)) {
    # Download and save the GBR reefs spatial data
    gbr_reefs_shp <- dhw::download_gbr_spatial(reefs = "")
    sf::st_write(gbr_reefs_shp, temp_file, overwrite = TRUE, quiet=TRUE)
  } else {
    # Read the existing file
    gbr_reefs_shp <- sf::st_read(temp_file, quiet=TRUE)
  }
  
  gbr_reefs_hull_buffered <- gbr_reefs_shp|> 
    sf::st_make_valid() |> 
    dplyr::filter(FEAT_NAME %in% c("Reef", "Terrestrial Reef")) |> 
    concaveman::concaveman() |> 
    sf::st_make_valid() |> 
    sf::st_buffer(1000) 
  
  # List all .nc files recursively
  rlist <- list.files(path = input, 
                      pattern = "\\.nc$", 
                      recursive = TRUE, 
                      full.names = TRUE)
  
  # Initialize list for processed rasters
  processed_rasters <- list()
  
  # Process each file
  for (file in rlist) {
    # Read raster
    r <- terra::rast(file)

    # Filter to include only 'sst_zlev=0'
    r <- r[["sst_zlev=0"]]

    # Set variable name and time dimension
    
    names(r) <- terra::time(r)
    
    # Crop raster to GBR region
    cropped_r <- terra::crop(r, gbr_reefs_hull_buffered)
    
    # Extract just the filename
    filename <- basename(file)
    
    # Create the new output path in the output folder
    new_path <- file.path(output, filename)
    
    # Save the cropped raster
   # terra::writeRaster(cropped_r, new_path, overwrite = TRUE)
    
    # Add processed raster to list
    processed_rasters <- c(processed_rasters, cropped_r)
    
    # Print status
    cat("Processed:", new_path, "\n")
  }
  
  # Combine all processed rasters into a single file if specified
  if (!is.null(combinedfilename)) {
    
    combined_raster <- do.call(c, processed_rasters) # Combine all rasters
    terra::writeRaster(combined_raster, combinedfilename, overwrite = TRUE)
    cat("Combined raster saved to:", combinedfilename, "\n")
  }
  
  
}

process_OISST(input = "/Volumes/Extreme_SSD/dhw/global",
  #            output = "/Volumes/Extreme_SSD/dhw/gbr",
              combinedfilename = "/Volumes/Extreme_SSD/dhw/gbr/GBR_OISST_full.nc",
              variable = "sst")
  
```

Alternatively, `cdo` offers a much faster workflow using `cdo mergetime *.nc outfile` and cropped to the GBR extent using`remapbil,target_grid_file.nc input.nc regridded_output.nc` (note: CDO does not directly support cropping to irregular polygons, so remapbil sets to the extent (bbox).


#### Extract ERA5

ERA5 doesn't have a direct `https` link as far as I'm aware. The `download_ERA5()` function uses the `ecmwfr` interface to 'ECMWF' and 'CDS' Data Web Services to access the daily SST data via [Copernicus](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels). Once downloaded, the `process_ERA5()` function combines the outputs to a single `rast` file.

```{r, eval=FALSE}

download_ERA5(
    start_year = 2024,
    end_year = 2024,
    ecmwfr_key = "381246a1-68c9-4e99-aab2-44c36d6da73d",
    timeout=60,
    dest_dir = "/Volumes/Extreme_SSD/dhw/ERA5/"
  )
  
  
tmp <- process_ERA5(folder = "/Volumes/Extreme_SSD/dhw/ERA5/gbr/", units = "celsius")



```
